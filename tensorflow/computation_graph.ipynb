{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow for Machine Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.random_normal([2, 20])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    out = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print out  # a 2x20 random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graph\n",
    "Each Tensorflow node is an **Operation** or **Op**. To create an operation, you call its associated Python operation or constructor. For example, \"constant\" takes a tensor input, and output several tensors the same as the input. Note that this simply add Ops to a graph behind the scenes, but **no computation** is actually taking place.\n",
    "Operations can be zero-input and zero-output. The operation in Tensorflow is more than just mathematical operations like add or sub. They can include *tasks* such as *initializing state*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define first Tensorflow graph\n",
    "a = tf.constant(5, name='input_a')   # constant is an Op\n",
    "b = tf.constant(3, name='input_b')\n",
    "c = tf.multiply(a, b, name='mul_c')\n",
    "d = tf.add(a, b, name='add_d')\n",
    "e = tf.add(c, d, name='add_e')\n",
    "# run the graph\n",
    "with tf.Session() as sess:\n",
    "    print \"e = %d\" % sess.run(e)\n",
    "    writer = tf.summary.FileWriter('./my_graph/computation_graph/example_1', sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define an equal graph with Tensor\n",
    "a = tf.constant([5, 3], name='input_a')\n",
    "b = tf.reduce_prod(a, name='prod_b')\n",
    "c = tf.reduce_sum(a, name='sum_c')\n",
    "d = tf.add(b, c, name='add_d')\n",
    "with tf.Session() as sess:\n",
    "    print \"d = %d\" % sess.run(d)\n",
    "    writer = tf.summary.FileWriter('./my_graph/computation_graph/example_2', sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Native Types and Numpy Arrays\n",
    "1. We can pass in Python native types, single values will be converted to 0-D Tensor (scalar), lists of values will be converted to a 1-D Tensor (vector), lists of lists of values will be converted to a 2-D Tensor (matrix) and so on.\n",
    "2. Numpy arrays can be directly passed into any TensorFlow Op.\n",
    "3. It really is best to start getting in the habit of being explicit about the numeric properties you want your Tensor objects to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow shape, can either be list or tuple\n",
    "s_3_flex = [2, None, None]\n",
    "a = tf.constant([5, 3], name='input_a')\n",
    "b = tf.reduce_prod(a, name='prod_b')\n",
    "c = tf.reduce_sum(a, name='sum_c')\n",
    "d = tf.add(b, c, name='add_d')\n",
    "shape = tf.shape(a, name='shape_d')\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(shape)  # tf.shape is also an Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overloaded operations\n",
    "Technically, the == operator is overloaded as well, but it will not return a Tensor of boolean values. Instead, it will return True if the two tensors being compared are the same object, and False otherwise. This is mainly used for internal purposes. If you’d like to check for equality or inequality, check out tf.equal() and tf.not_equal, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow graphs\n",
    "As a convenience, TensorFlow automatically creates a Graph when the library is loaded and assigns it to be the default. Thus, any Operations, tensors, etc. defined outside of a *Graph.as_default()* context manager will automatically be placed in the default graph.<br/>\n",
    "When defining multiple graphs in one file, it's best practice to either not use the default graph or immediately\n",
    "assign a handle to it.<br/>\n",
    "Additionally, it is possible to load in previously defined models from other TensorFlow scripts and assign them to Graph objects using a combination of the *Graph.as_graph_def()* and *tf.import_graph_def* functions. Thus, a user can compute and use the output of several separate models in the same Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiple graph example\n",
    "import tensorflow as tf\n",
    "g1 = tf.Graph()\n",
    "g2 = tf.Graph()\n",
    "# or we use get a handle to default graph like g2 = tf.get_default_graph()\n",
    "with g1.as_default():\n",
    "    pass\n",
    "\n",
    "with g2.as_default():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow sessions\n",
    "tf.Session(target=None, graph=default_graph, config=default)\n",
    "1. target specifies the execution engine to use. For most applications, this will be left at its default empty string value. When using sessions in a distributed setting, this parameter is used to connect to tf.train.Server instances (covered in the later chapters of this book).\n",
    "2. graph specifies the Graph object that will be launched in the Session. The default value is None, which indicates that the current default graph should be used. When using multiple graphs, it’s best to explicitly pass in the Graph you’d like to run (instead of creating the Session inside of a with block).\n",
    "3. config allows users to specify options to configure the session, such as limiting the number of CPUs or GPUs to use, setting optimization parameters for graphs, and logging options.\n",
    "\n",
    "tf.Session.run(fetches, feed_dict=None, options=\"\", run_metadata=\"\")\n",
    "1. fetches is a required argument, which can be any graph element including **Operations** or **Tensor** Object. If the requested object is a Tensor, then the output of run() will be a NumPy array. If the object is an Operation, then the output will be None. When fetches is a list, the output of run() will be a list with values corresponding to the output of the requested elements. \"Operations\" example: *tf.initialize_all_variables()*, that is a useful side-effect when run.\n",
    "2. The parameter feed_dict is used to override Tensor values in the graph, and it expects a Python dictionary object as input. It is very useful when you have a large graph and want to test out part of it with dummy values, TensorFlow won’t waste time with unnecessary computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use session as context manager\n",
    "import tensorflow as tf\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    a = tf.random_normal((2, 20))\n",
    "    sess = tf.Session()\n",
    "    print a.eval(session=sess)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholders**, as the name implies, act as if they are Tensor objects, but they do not have their values specified when created. Instead, they hold the place for a Tensor that will be fed at runtime, in effect becoming an “input” node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Creates a placeholder vector of length 2 with data type int32\n",
    "a = tf.placeholder(tf.int32, shape=[2], name=\"my_input\")\n",
    "# Use the placeholder as if it were any other Tensor object\n",
    "b = tf.reduce_prod(a, name=\"prod_b\")\n",
    "c = tf.reduce_sum(a, name=\"sum_c\")\n",
    "# Finish off the graph\n",
    "d = tf.add(b, c, name=\"add_d\")\n",
    "\n",
    "# Open a TensorFlow Session\n",
    "sess = tf.Session()\n",
    "# Create a dictionary to pass into `feed_dict`\n",
    "# Key: `a`, the handle to the placeholder's output Tensor\n",
    "# Value: A vector with value [5, 3] and int32 data type\n",
    "input_dict = {a: np.array([5, 3], dtype=np.int32)}\n",
    "# Fetch the value of `d`, feeding the values of `input_vector` into `a`\n",
    "result = sess.run(d, feed_dict=input_dict)\n",
    "print result\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables** objects, which contain mutable tensor values that persist across multiple calls to *Session.run()*. Note that **Tensor** and **Operations** are immutable objects.<br/>\n",
    "**Variable Initialization**\n",
    "Variables have an extra step involved in order to use them- you *must* initialize the Variable within a Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2x2 matrix of  zeros\n",
    "zeros = tf.zeros([2, 2])\n",
    "# vector of length 6 of ones\n",
    "ones = tf.ones([6])\n",
    "# 3x3x3 Tensor of random uniform  values between 0 and 10\n",
    "uniform = tf.random_uniform([3, 3, 3], minval=0, maxval=10)\n",
    "# 3x3x3 Tensor of normally distributed numbers; mean 0 and standard deviation 2\n",
    "normal = tf.random_normal([3, 3, 3], mean=0.0, stddev=2.0)\n",
    "# No values below 3.0 or above 7.0 will be returned in this Tensor\n",
    "trunc = tf.truncated_normal([2, 2], mean=5.0, stddev=1.0)\n",
    "# pass Operations to tf Variable\n",
    "# Default value of mean=0.0\n",
    " # Default value of stddev=1.0\n",
    "random_var = tf.Variable(tf.truncated_normal([2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable initialization\n",
    "var1 = tf.Variable(0, name=\"initialize_me\")\n",
    "var2 = tf.Variable(1, name=\"no_initialization\")\n",
    "init = tf.variables_initializer([var1], name=\"init_var1\")\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# changing variables\n",
    "# Create variable with starting value of 1\n",
    "my_var = tf.Variable(1)\n",
    "# Create an operation that multiplies the variable by 2 each time it is run\n",
    "my_var_times_two = my_var.assign(my_var * 2)\n",
    "# Initialization operation\n",
    "init = tf.global_variables_initializer()\n",
    "# Start a session\n",
    "sess = tf.Session()\n",
    "# Initialize variable\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply variable by two and return it\n",
    "sess.run(my_var_times_two)\n",
    "## OUT: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply again\n",
    "sess.run(my_var_times_two)\n",
    "## OUT: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply again\n",
    "sess.run(my_var_times_two)\n",
    "## OUT: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset my_var\n",
    "sess.run(my_var.initializer)  # only reset my_var instead of global reset all the variables\n",
    "sess.run(my_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainable**: variables are created with trainable features, that can be automatically changed by tf.optimizer object. In some cases, we want to set trainable to False. e.g. step counters or transfer learning and finetuning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing your graph with name scopes\n",
    "To manage complexity and hierarchy of large graphs, ensorFlow currently offers a mechanism to help organize your graphs: name scopes. Essentially, name scopes allow you to group Operations into larger, named blocks. Then, when you launch your graph with TensorBoard, each name scope will encapsulate its own Ops, making the visualization much more digestible.<br/>\n",
    "Separating a huge graph into meaningful clusters can make understanding and debugging your model a much more approachable task.<br/>\n",
    "tf.constant objects don’t behave quite the same way as other Tensors or Operations when displayed in TensorBoard. Even though we declared static_value outside of any name scope, it still gets placed inside them. The basic idea for this is that constants can be used at any time and don’t necessarily need to be used in any particular order. To prevent arrows flying all over the graph from a single point, it just makes a little small impression whenever a constant is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.name_scope(\"Scope_A\"):\n",
    "    a = tf.add(1, 2, name=\"A_add\")\n",
    "    b = tf.multiply(a, 3, name=\"A_mul\")\n",
    "with tf.name_scope(\"Scope_B\"):\n",
    "    c = tf.add(4, 5, name=\"B_add\")\n",
    "    d = tf.multiply(c, 6, name=\"B_mul\")\n",
    "e = tf.add(b, d, name=\"output\")\n",
    "writer = tf.summary.FileWriter('./my_graph/computation_graph/name_scope', graph=tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use fft to compute conv2d\n",
    "import tensorflow as tf\n",
    "X = tf.Variable(tf.truncated_normal([128, 32, 32, 3]))\n",
    "kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 32]))\n",
    "bias = tf.Variable(tf.truncated_normal([32]))\n",
    "output = tf.nn.conv2d(X, kernel, strides=[1, 1, 1, 1], padding=\"SAME\") + bias\n",
    "dX, dKernel, dBias = tf.gradients(output, [X, kernel, bias])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "dX_value, dKernel_value, dBias_value = sess.run([dX, dKernel, dBias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dX_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dKernel_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
